{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2941fff4-9142-468f-aab5-fd03b5af76a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d0ab54-7ff0-4732-b0dc-ae4f1c5fb529",
   "metadata": {},
   "source": [
    "## ESOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b7bb93-28b6-450a-9044-3a21d718dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'ESOL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70cec6fc-0316-4e5b-9127-d8a2b2b98978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# esol_model_perf = {}\n",
    "esol_model_perf = utils_benchmark.load_model_perf(task_name)\n",
    "len(esol_model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c1e976b-9b65-42b4-9bee-707400f3e0bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of compounds: 1084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /mnt/data2/morgan-bert/MorganBERT_models/MorganBERT_base_full_r_0_s_0 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1650' max='1650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1650/1650 06:17, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.614200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.129400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.075600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /mnt/data2/morgan-bert/MorganBERT_models/MorganBERT_base_full_r_0_s_0 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1650' max='1650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1650/1650 06:20, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.653300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.122600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.062600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /mnt/data2/morgan-bert/MorganBERT_models/MorganBERT_base_full_r_0_s_0 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1650' max='1650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1650/1650 06:20, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.627600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.132100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.070300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /mnt/data2/morgan-bert/MorganBERT_models/MorganBERT_base_full_r_0_s_0 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1650' max='1650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1650/1650 06:20, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.559000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.131400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.064400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /mnt/data2/morgan-bert/MorganBERT_models/MorganBERT_base_full_r_0_s_0 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1650' max='1650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1650/1650 06:20, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.579300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.122900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.064300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esol_model_perf = utils_benchmark.run_benchmark(task_name, esol_model_perf)\n",
    "len(esol_model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d3214b-0019-4428-9660-349a5a2ae686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- eval_mse --------------------\n",
      "KNN 2.290 $\\pm$ 0.579\n",
      "RF+MACCS 1.911 $\\pm$ 0.467\n",
      "RF+PubChemFP 1.727 $\\pm$ 0.381\n",
      "RF+ECFP2 3.309 $\\pm$ 0.633\n",
      "RF+ECFP4 3.138 $\\pm$ 0.553\n",
      "RF+Daylight 3.660 $\\pm$ 0.960\n",
      "RF+RDKitFP 3.026 $\\pm$ 0.562\n",
      "D-MPNN 0.911 $\\pm$ 0.201\n",
      "MolCLR 2.167 $\\pm$ 0.295\n",
      "ChemBERTa-10M-MLM 1.176 $\\pm$ 0.289\n",
      "ChemBERTa-77M-MLM 1.511 $\\pm$ 0.206\n",
      "MolFormer 0.758 $\\pm$ 0.108\n",
      "MorganBERT_base_full_r_0_s_0 0.876 $\\pm$ 0.235\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_20 0.841 $\\pm$ 0.175\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_300 0.876 $\\pm$ 0.108\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_20 0.788 $\\pm$ 0.132\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_300 0.754 $\\pm$ 0.129\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_2300 0.956 $\\pm$ 0.261\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_9000 0.773 $\\pm$ 0.133\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_2300 0.670 $\\pm$ 0.103\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_9000 0.811 $\\pm$ 0.155\n",
      "\n",
      "\n",
      "-------------------- eval_mae --------------------\n",
      "KNN 1.145 $\\pm$ 0.139\n",
      "RF+MACCS 1.078 $\\pm$ 0.113\n",
      "RF+PubChemFP 0.990 $\\pm$ 0.097\n",
      "RF+ECFP2 1.412 $\\pm$ 0.137\n",
      "RF+ECFP4 1.370 $\\pm$ 0.124\n",
      "RF+Daylight 1.442 $\\pm$ 0.168\n",
      "RF+RDKitFP 1.323 $\\pm$ 0.108\n",
      "D-MPNN 0.730 $\\pm$ 0.088\n",
      "MolCLR 1.176 $\\pm$ 0.071\n",
      "ChemBERTa-10M-MLM 0.835 $\\pm$ 0.097\n",
      "ChemBERTa-77M-MLM 0.938 $\\pm$ 0.055\n",
      "MolFormer 0.676 $\\pm$ 0.053\n",
      "MorganBERT_base_full_r_0_s_0 0.697 $\\pm$ 0.082\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_20 0.713 $\\pm$ 0.072\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_300 0.729 $\\pm$ 0.040\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_20 0.694 $\\pm$ 0.047\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_300 0.669 $\\pm$ 0.041\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_2300 0.757 $\\pm$ 0.087\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_9000 0.683 $\\pm$ 0.049\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_2300 0.637 $\\pm$ 0.046\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_9000 0.690 $\\pm$ 0.058\n",
      "\n",
      "\n",
      "-------------------- eval_r2 --------------------\n",
      "KNN 0.501 $\\pm$ 0.133\n",
      "RF+MACCS 0.584 $\\pm$ 0.087\n",
      "RF+PubChemFP 0.625 $\\pm$ 0.069\n",
      "RF+ECFP2 0.273 $\\pm$ 0.175\n",
      "RF+ECFP4 0.313 $\\pm$ 0.140\n",
      "RF+Daylight 0.208 $\\pm$ 0.185\n",
      "RF+RDKitFP 0.335 $\\pm$ 0.150\n",
      "D-MPNN 0.800 $\\pm$ 0.043\n",
      "MolCLR 0.524 $\\pm$ 0.084\n",
      "ChemBERTa-10M-MLM 0.745 $\\pm$ 0.056\n",
      "ChemBERTa-77M-MLM 0.668 $\\pm$ 0.057\n",
      "MolFormer 0.827 $\\pm$ 0.029\n",
      "MorganBERT_base_full_r_0_s_0 0.807 $\\pm$ 0.055\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_20 0.816 $\\pm$ 0.035\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_300 0.808 $\\pm$ 0.026\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_20 0.826 $\\pm$ 0.038\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_300 0.835 $\\pm$ 0.026\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_2300 0.794 $\\pm$ 0.040\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_9000 0.831 $\\pm$ 0.027\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_2300 0.854 $\\pm$ 0.020\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_9000 0.823 $\\pm$ 0.031\n",
      "\n",
      "\n",
      "-------------------- eval_rmse --------------------\n",
      "KNN 1.503 $\\pm$ 0.201\n",
      "RF+MACCS 1.374 $\\pm$ 0.164\n",
      "RF+PubChemFP 1.308 $\\pm$ 0.147\n",
      "RF+ECFP2 1.812 $\\pm$ 0.176\n",
      "RF+ECFP4 1.765 $\\pm$ 0.162\n",
      "RF+Daylight 1.898 $\\pm$ 0.266\n",
      "RF+RDKitFP 1.733 $\\pm$ 0.164\n",
      "D-MPNN 0.950 $\\pm$ 0.100\n",
      "MolCLR 1.469 $\\pm$ 0.101\n",
      "ChemBERTa-10M-MLM 1.077 $\\pm$ 0.144\n",
      "ChemBERTa-77M-MLM 1.227 $\\pm$ 0.084\n",
      "MolFormer 0.869 $\\pm$ 0.063\n",
      "MorganBERT_base_full_r_0_s_0 0.930 $\\pm$ 0.123\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_20 0.913 $\\pm$ 0.096\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_300 0.935 $\\pm$ 0.058\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_20 0.885 $\\pm$ 0.074\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_300 0.866 $\\pm$ 0.072\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_2300 0.971 $\\pm$ 0.128\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_9000 0.877 $\\pm$ 0.075\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_2300 0.816 $\\pm$ 0.063\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_9000 0.897 $\\pm$ 0.089\n",
      "\n",
      "\n",
      "-------------------- eval_pcc --------------------\n",
      "KNN 0.743 $\\pm$ 0.063\n",
      "RF+MACCS 0.777 $\\pm$ 0.047\n",
      "RF+PubChemFP 0.816 $\\pm$ 0.027\n",
      "RF+ECFP2 0.618 $\\pm$ 0.078\n",
      "RF+ECFP4 0.657 $\\pm$ 0.060\n",
      "RF+Daylight 0.535 $\\pm$ 0.098\n",
      "RF+RDKitFP 0.646 $\\pm$ 0.056\n",
      "D-MPNN 0.910 $\\pm$ 0.016\n",
      "MolCLR 0.783 $\\pm$ 0.045\n",
      "ChemBERTa-10M-MLM 0.867 $\\pm$ 0.032\n",
      "ChemBERTa-77M-MLM 0.841 $\\pm$ 0.029\n",
      "MolFormer 0.922 $\\pm$ 0.010\n",
      "MorganBERT_base_full_r_0_s_0 0.906 $\\pm$ 0.026\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_20 0.915 $\\pm$ 0.021\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_300 0.910 $\\pm$ 0.019\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_20 0.917 $\\pm$ 0.019\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_300 0.918 $\\pm$ 0.016\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_2300 0.908 $\\pm$ 0.012\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_9000 0.919 $\\pm$ 0.018\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_2300 0.929 $\\pm$ 0.011\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_9000 0.914 $\\pm$ 0.015\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils_benchmark.print_perf_table(esol_model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54889800-491e-4375-9d00-e762d2285142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
