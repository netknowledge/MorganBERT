{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73063d4e-0067-48ed-a468-0847942246b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e9459-e227-436e-9bfe-b56ac687c31a",
   "metadata": {},
   "source": [
    "## AZ-sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2915a60-71f5-4a80-b8c1-1107c111a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'AZ-sol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "372ab88d-f20f-4b92-a739-7f4b07e945b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# az_sol_model_perf = {}\n",
    "az_sol_model_perf = utils_benchmark.load_model_perf(task_name)\n",
    "len(az_sol_model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab77addc-5e24-4563-8fde-53e64c480051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of compounds: 1763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /mnt/data2/morgan-bert/MorganBERT_models/MorganBERT_base_full_r_0_s_0 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2670' max='2670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2670/2670 10:26, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.748700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.089200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.055100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.038400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /mnt/data2/morgan-bert/MorganBERT_models/MorganBERT_base_full_r_0_s_0 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2670' max='2670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2670/2670 10:29, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.674100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.180300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.057800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.040200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /mnt/data2/morgan-bert/MorganBERT_models/MorganBERT_base_full_r_0_s_0 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2670' max='2670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2670/2670 10:29, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.707800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.181700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.087000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.055900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /mnt/data2/morgan-bert/MorganBERT_models/MorganBERT_base_full_r_0_s_0 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2670' max='2670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2670/2670 10:29, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.717700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.154800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.081900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.034800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /mnt/data2/morgan-bert/MorganBERT_models/MorganBERT_base_full_r_0_s_0 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2670' max='2670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2670/2670 10:29, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.163100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.082400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.048800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.034600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/administrator/miniconda3/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az_sol_model_perf = utils_benchmark.run_benchmark(task_name, az_sol_model_perf)\n",
    "len(az_sol_model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5eaf505-baf5-415e-9c39-3feeb5790762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- eval_mse --------------------\n",
      "KNN 0.851 $\\pm$ 0.095\n",
      "RF+MACCS 0.691 $\\pm$ 0.072\n",
      "RF+PubChemFP 0.662 $\\pm$ 0.059\n",
      "RF+ECFP2 0.727 $\\pm$ 0.047\n",
      "RF+ECFP4 0.732 $\\pm$ 0.049\n",
      "RF+Daylight 0.742 $\\pm$ 0.032\n",
      "RF+RDKitFP 0.749 $\\pm$ 0.038\n",
      "D-MPNN 0.684 $\\pm$ 0.094\n",
      "MolCLR 0.783 $\\pm$ 0.098\n",
      "ChemBERTa-10M-MLM 0.902 $\\pm$ 0.099\n",
      "ChemBERTa-77M-MLM 0.749 $\\pm$ 0.064\n",
      "MolFormer 0.917 $\\pm$ 0.196\n",
      "MorganBERT_base_full_r_0_s_0 0.763 $\\pm$ 0.034\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_20 0.815 $\\pm$ 0.067\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_300 0.786 $\\pm$ 0.030\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_20 0.723 $\\pm$ 0.046\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_300 0.719 $\\pm$ 0.051\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_2300 0.768 $\\pm$ 0.079\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_9000 0.771 $\\pm$ 0.067\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_2300 0.745 $\\pm$ 0.099\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_9000 0.718 $\\pm$ 0.058\n",
      "\n",
      "\n",
      "-------------------- eval_mae --------------------\n",
      "KNN 0.734 $\\pm$ 0.048\n",
      "RF+MACCS 0.682 $\\pm$ 0.045\n",
      "RF+PubChemFP 0.664 $\\pm$ 0.037\n",
      "RF+ECFP2 0.697 $\\pm$ 0.025\n",
      "RF+ECFP4 0.695 $\\pm$ 0.028\n",
      "RF+Daylight 0.714 $\\pm$ 0.026\n",
      "RF+RDKitFP 0.717 $\\pm$ 0.030\n",
      "D-MPNN 0.662 $\\pm$ 0.049\n",
      "MolCLR 0.730 $\\pm$ 0.053\n",
      "ChemBERTa-10M-MLM 0.778 $\\pm$ 0.052\n",
      "ChemBERTa-77M-MLM 0.697 $\\pm$ 0.028\n",
      "MolFormer 0.778 $\\pm$ 0.079\n",
      "MorganBERT_base_full_r_0_s_0 0.702 $\\pm$ 0.029\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_20 0.708 $\\pm$ 0.043\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_300 0.700 $\\pm$ 0.013\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_20 0.674 $\\pm$ 0.020\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_300 0.674 $\\pm$ 0.031\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_2300 0.701 $\\pm$ 0.041\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_9000 0.694 $\\pm$ 0.035\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_2300 0.687 $\\pm$ 0.046\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_9000 0.687 $\\pm$ 0.030\n",
      "\n",
      "\n",
      "-------------------- eval_r2 --------------------\n",
      "KNN 0.073 $\\pm$ 0.110\n",
      "RF+MACCS 0.249 $\\pm$ 0.063\n",
      "RF+PubChemFP 0.280 $\\pm$ 0.066\n",
      "RF+ECFP2 0.209 $\\pm$ 0.048\n",
      "RF+ECFP4 0.204 $\\pm$ 0.047\n",
      "RF+Daylight 0.193 $\\pm$ 0.028\n",
      "RF+RDKitFP 0.185 $\\pm$ 0.037\n",
      "D-MPNN 0.259 $\\pm$ 0.071\n",
      "MolCLR 0.150 $\\pm$ 0.080\n",
      "ChemBERTa-10M-MLM 0.014 $\\pm$ 0.149\n",
      "ChemBERTa-77M-MLM 0.186 $\\pm$ 0.058\n",
      "MolFormer -1.024 $\\pm$ 0.552\n",
      "MorganBERT_base_full_r_0_s_0 0.169 $\\pm$ 0.055\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_20 0.110 $\\pm$ 0.106\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_300 0.144 $\\pm$ 0.051\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_20 0.213 $\\pm$ 0.057\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_300 0.216 $\\pm$ 0.070\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_2300 0.166 $\\pm$ 0.063\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_9000 0.160 $\\pm$ 0.088\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_2300 0.191 $\\pm$ 0.095\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_9000 0.219 $\\pm$ 0.049\n",
      "\n",
      "\n",
      "-------------------- eval_rmse --------------------\n",
      "KNN 0.922 $\\pm$ 0.052\n",
      "RF+MACCS 0.830 $\\pm$ 0.043\n",
      "RF+PubChemFP 0.813 $\\pm$ 0.036\n",
      "RF+ECFP2 0.853 $\\pm$ 0.028\n",
      "RF+ECFP4 0.855 $\\pm$ 0.029\n",
      "RF+Daylight 0.861 $\\pm$ 0.019\n",
      "RF+RDKitFP 0.865 $\\pm$ 0.022\n",
      "D-MPNN 0.825 $\\pm$ 0.057\n",
      "MolCLR 0.884 $\\pm$ 0.054\n",
      "ChemBERTa-10M-MLM 0.948 $\\pm$ 0.052\n",
      "ChemBERTa-77M-MLM 0.865 $\\pm$ 0.037\n",
      "MolFormer 0.953 $\\pm$ 0.100\n",
      "MorganBERT_base_full_r_0_s_0 0.874 $\\pm$ 0.019\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_20 0.902 $\\pm$ 0.037\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_300 0.886 $\\pm$ 0.017\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_20 0.850 $\\pm$ 0.027\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_300 0.848 $\\pm$ 0.031\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_2300 0.875 $\\pm$ 0.046\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_9000 0.877 $\\pm$ 0.038\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_2300 0.862 $\\pm$ 0.057\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_9000 0.847 $\\pm$ 0.035\n",
      "\n",
      "\n",
      "-------------------- eval_pcc --------------------\n",
      "KNN 0.403 $\\pm$ 0.078\n",
      "RF+MACCS 0.500 $\\pm$ 0.063\n",
      "RF+PubChemFP 0.532 $\\pm$ 0.058\n",
      "RF+ECFP2 0.464 $\\pm$ 0.043\n",
      "RF+ECFP4 0.458 $\\pm$ 0.045\n",
      "RF+Daylight 0.444 $\\pm$ 0.031\n",
      "RF+RDKitFP 0.437 $\\pm$ 0.040\n",
      "D-MPNN 0.554 $\\pm$ 0.056\n",
      "MolCLR 0.419 $\\pm$ 0.067\n",
      "ChemBERTa-10M-MLM 0.532 $\\pm$ 0.050\n",
      "ChemBERTa-77M-MLM 0.499 $\\pm$ 0.046\n",
      "MolFormer 0.503 $\\pm$ 0.065\n",
      "MorganBERT_base_full_r_0_s_0 0.523 $\\pm$ 0.032\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_20 0.536 $\\pm$ 0.041\n",
      "MorganBERT_base_full_r_1_s_0_atomFirst_f_300 0.547 $\\pm$ 0.030\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_20 0.549 $\\pm$ 0.031\n",
      "MorganBERT_base_full_r_1_s_0_radiusFirst_f_300 0.563 $\\pm$ 0.045\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_2300 0.545 $\\pm$ 0.051\n",
      "MorganBERT_base_full_r_2_s_0_atomFirst_f_9000 0.550 $\\pm$ 0.048\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_2300 0.535 $\\pm$ 0.066\n",
      "MorganBERT_base_full_r_2_s_0_radiusFirst_f_9000 0.540 $\\pm$ 0.031\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils_benchmark.print_perf_table(az_sol_model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e56a3-5df5-46c2-8853-cb185fecb910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
